{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabfd305-59ca-4d5f-b319-b7151f135a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7346704e-c584-4431-8c28-5282e76c8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f82299-7ba4-4229-b3da-7b1ee47f358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9110ff05-8603-4916-83a3-909926251190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import get_cfg_defaults\n",
    "from core.datasets.dataset_loading_utils import load_dataset\n",
    "from core.datasets.vq_dataset import DATALoader\n",
    "from utils.vis_utils import plot_3d_global\n",
    "from core.models.conformer_vqvae import ConformerVQMotionModel, Encoder\n",
    "from torch.utils import data\n",
    "from core.datasets.vq_dataset import DATALoader, MotionCollator\n",
    "from einops import pack, rearrange, reduce, repeat, unpack\n",
    "\n",
    "def pack_one(t, pattern):\n",
    "    return pack([t], pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e790c066-3169-472f-b9e2-9d4773b86569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vis_utils.render_final import Renderer\n",
    "renderer = Renderer(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ba701-a4a9-4e72-8158-4fee24ab019c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782bde2e-f8b9-4d44-8a92-01c6913ee68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading config from: /srv/hays-lab/scratch/sanisetty3/music_motion/TGM3D/checkpoints/conformer_768_1024_affine_varlen/conformer_768_1024_affine_varlen.yaml\n"
     ]
    }
   ],
   "source": [
    "path = \"/srv/hays-lab/scratch/sanisetty3/music_motion/TGM3D/checkpoints/conformer_768_1024_affine_varlen/conformer_768_1024_affine_varlen.yaml\"\n",
    "cfg = get_cfg_defaults()\n",
    "print(\"loading config from:\", path)\n",
    "cfg.merge_from_file(path)\n",
    "cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d1b22e-94ee-4e65-96e0-2fbb47a048e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.conformer_vqvae import ConformerVQMotionModel, Encoder\n",
    "convvq = ConformerVQMotionModel(cfg.vqvae).to(device).eval()\n",
    "convvq.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/TGM3D/checkpoints/conformer_512_1024_affine/vqvae_motion.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5db0c61-4447-4fd1-b7df-708828aaa2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.datasets.vq_dataset import VQMotionDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0a0544fc-47d1-41a9-a2f1-39853636e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 6221/6221 [00:04<00:00, 1471.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 6221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = VQMotionDataset(\"t2m\" , \"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotionSMPL\" , window_size = -1, split = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d04642-c1b3-4dd1-81e9-85a501297d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f90ff4ef-c578-4059-b32d-f9b92541444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DATALoader(\n",
    "            train_ds,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            collate_fn=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3b1f28f4-85d3-47d5-8f21-52db9c34b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0ee5717e-4508-4a34-901a-f8e8672664b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = \"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotionSMPLIndices/HumanML3D_SMPL/joint_indices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e379da16-09be-4606-abb0-2ac0cb3d8efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 6221/6221 [04:07<00:00, 25.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm(train_dl)):\n",
    "    # if i < 12300:\n",
    "    #     continue\n",
    "    \n",
    "    gt_motion = batch[\"motion\"].to(device)\n",
    "    if gt_motion.shape[1] > 1000:\n",
    "        ind = []\n",
    "        for m in range(0, gt_motion.shape[1], 1000):\n",
    "            indics = convvq.encode(gt_motion[:, m:m+1000])\n",
    "            ind.append(indics[0])\n",
    "        indices = torch.cat(ind)[None]\n",
    "    else:\n",
    "        indices = convvq.encode(gt_motion)\n",
    "    np.save(os.path.join(dest , batch[\"names\"][0]+\".npy\") , indices.detach().cpu().numpy())\n",
    "    del indices\n",
    "    del gt_motion\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91969d6-e88d-47f2-aae2-ae55f42e306d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d666be5-1052-4fe7-be3a-fb86d1fd85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from glob import glob\n",
    "# glob(\"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotionSMPLIndices/HumanML3D_SMPL/joint_indices/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694383f4-f903-49f4-8091-22f011304d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf3bdc-41cf-4df0-9ab6-1940e3ed28c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc1010a9-b4e4-4a2c-97c8-df5899c85e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "og = \"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotionSMPL/Choreomaster_SMPL/new_joint_vecs/00_1093.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "29af84f2-3c27-447c-9bdc-269820e0ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotionSMPLIndices/Choreomaster_SMPL/joint_indices/00_1093.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2fd06b9e-10ef-4aa7-a1d9-5ab75c986718",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = torch.Tensor(np.load(src))\n",
    "ogg = torch.Tensor(np.load(og))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "87b3c405-7489-4df8-b712-5455a805419c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 866])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8a30a9c6-cb17-4030-8c82-c0c0d66316d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized, decoded_motion_features = convvq.decode(ind.long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b5ee80c-d17c-4194-8da5-8d43970852a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3464, 271])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_motion_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f54e14dd-554c-4bfc-a4b9-bec8496d939a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3464, 271])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ogg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3320e-1e06-45fe-87b8-044d9d74e4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "56c066d3-cd58-47ae-afa0-66e71517022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer.render(\n",
    "    motion_vec=train_ds.inv_transform(decoded_motion_features)[0,:1000,:135],\n",
    "    outdir=\"./renders/\",\n",
    "    step=0,\n",
    "    name=f\"00_000007_pred\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "afe3d6cd-c3b4-4b34-bdfb-3c2810b66def",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer.render(\n",
    "    motion_vec=ogg[:1000,:135],\n",
    "    outdir=\"./renders/\",\n",
    "    step=0,\n",
    "    name=f\"00_000007_og\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd0c2e-bec7-47bc-b115-5c59078ebfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "25bef9be-44eb-44c9-992f-6a2356f5b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hml = \"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotion/HumanML3D/Std.npy\"\n",
    "hml2 = \"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotion/AIST/Std.npy\"\n",
    "hml3 = \"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotion/Choreomaster/Std.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "268210f1-5360-4eb4-b256-069a8bf897c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotion/Std.npy\" , np.mean([np.load(hml) + np.load(hml2) + np.load(hml3)] , 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d869b8-f7d6-47dd-889f-af852f8f22bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c71ac0fc-62aa-4b5f-ad6a-7867c1a7d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "db0eccd4-791d-4386-b107-bcff752f6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "pths = sorted(glob(\"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotion/HumanML3D/new_joint_vecs/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aecd03dc-f424-4e79-841b-d505cf7c5443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotion/HumanML3D/new_joint_vecs/M008676.npy'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pths[25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "47310a88-0986-4cde-b532-e7ea13b1db5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8676"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(pths[25000].split(\"/\")[-1].split(\".\")[0][-6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8eff3e1e-adb4-42fa-bd00-4cf93073bad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 32648/32648 [00:00<00:00, 964613.99it/s]\n"
     ]
    }
   ],
   "source": [
    "add = []\n",
    "for p in tqdm(pths):\n",
    "    nm = int(p.split(\"/\")[-1].split(\".\")[0][-6:])\n",
    "    if nm > 14616:\n",
    "        add.append(p.split(\"/\")[-1].split(\".\")[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "59791185-879b-4e1e-b45c-85be057e000f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "with open(r'/srv/hays-lab/scratch/sanisetty3/music_motion/HumanMotion/HumanML3D/train.txt', 'a') as fp:\n",
    "    for item in add:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5b9d3c0b-51e0-4b6a-aabb-533b387cee42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3418"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "546060ca-56b9-40dc-93a8-d57fd9a43d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 32648/32648 [00:00<00:00, 1130149.03it/s]\n"
     ]
    }
   ],
   "source": [
    "add = []\n",
    "for p in tqdm(pths):\n",
    "    n = p.split(\"/\")[-1].split(\".\")[0]\n",
    "    add.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2ac9da65-d194-4b66-b00a-84ad44969eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9329c4-7e76-496b-b0a5-2fa740078a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2e432-d743-4817-9929-ccf9acc2c802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e93f5cac-35b5-4e7c-a934-6913fad00b0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## VQVARLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e255c3-4192-485e-9447-621fb2286e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363778e-4343-4c00-b9e8-be9b02e1c3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04844221-8cf0-4124-a8bf-f647efff9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.vis_utils.write_obj import main\n",
    "# main(model_folder=\"/srv/hays-lab/scratch/sanisetty3/music_motion/motion_vqvae/body_models/smplh/SMPLH_NEUTRAL.npz\", motion_file = \"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanML3D/amass_data/ACCAD/Male1Running_c3d/Run C24 - quick side step left_poses.npz\" , output_folder = \"./renders/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "944bf669-f1b4-4c9a-997a-fded5fd5cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17c93f1a-eafe-471c-a550-b1c3e9ffcaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hml = sorted(glob(\"/srv/hays-lab/scratch/sanisetty3/music_motion/HumanML3D/HumanML3D/new_joint_vecs/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feb0cc41-52ec-499e-9b1d-c1606cf89b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000676'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hml[17000].split(\"/\")[-1].split(\".\")[0][-6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5140f4dc-82a4-4d1e-bfb5-0c3ec9285693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 32648/32648 [00:13<00:00, 2382.97it/s]\n"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "for i in tqdm(hml):\n",
    "    name = int(i.split(\"/\")[-1].split(\".\")[0][-6:])\n",
    "    if name > 14616:\n",
    "        continue\n",
    "\n",
    "    lens.append(np.load(i).shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3e1bc-e792-41b4-ade9-ec7fec1cbd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600d600-bb4a-4aad-a721-c3268da24241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95665bd-ac4c-4b39-996d-325c9d4b93b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3b8df-36cc-466c-bfcb-6432b3f94319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb614a4-29b9-4994-ba6f-f6737ab590ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26660a-bd78-40e8-a86a-51c9def316e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9447fe5-7758-4ff5-b406-689f80feafc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ef6ea7f2-41c7-41a3-bff9-4a66db89f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.conformer import ConformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46c3c202-be94-490c-bac4-97384a69e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ff40a-b67b-45c1-b2c6-574bf92481df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de4e5af1-e705-4a34-a73f-097ddfd21bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in valid_dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aaeabbf2-2282-4fac-b428-97c0dd8beee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_motion = batch[\"motion\"].to(device)\n",
    "mask = batch.get(\"motion_mask\", None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2115201d-43a0-4d95-a6a6-2c0fccffd668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([105])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "547544fe-a3f0-4a6c-bb31-f9f19e7dfef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 80, 768])\n",
      "torch.Size([4, 40, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for l in enc.blocks:\n",
    "    if isinstance(l, ConformerBlock):\n",
    "        print(x.shape)\n",
    "        x = l(x,mask)\n",
    "        mask = torch.nn.functional.max_pool1d(mask.float() , 3 ,stride = 2, padding = 1).bool()\n",
    "    else:\n",
    "        x = l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b98a24-5f9f-4ec5-99a2-edc0fa608b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b96408-acbe-4bcb-8d12-32eb62743d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab772133-88ef-4456-8be1-045d5f1956b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = torch.nn.functional.max_pool1d(mask.float() , 3 ,stride = 2, padding = 1).bool()\n",
    "mask2 = torch.nn.functional.max_pool1d(mask1.float() , 3 ,stride = 2, padding = 1).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70f14ee1-1e7a-4ff4-9cee-ce46415bdee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 53])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51242b74-be0e-49c6-bc79-8387357d6a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "947a7482-562e-44d4-8fbf-aa14fcf9827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask3 = torch.nn.functional.upsample(mask2[None].float() , scale_factor=2, mode=\"nearest\")[0, :,:-1]\n",
    "# mask3 = torch.nn.functional.max_pool1d(mask3 , 3 ,stride = 1, padding = 1)\n",
    "mask4 = torch.nn.functional.upsample(mask3[None].float() , scale_factor=2, mode=\"nearest\")[0, :,:-1]\n",
    "# mask4 = torch.nn.functional.max_pool1d(mask4 , 3 ,stride = 1, padding = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "76d66ac3-4bb5-439b-8f67-d8845b2b202a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "25960d6c-9613-4725-8522-6052e2d2d185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1[1].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a7615585-2028-4b37-a9c9-94b7aee8a5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask4[1].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc37a5d3-7f3e-45b4-ae24-9d68bca9cf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a61bfe16-9422-45ac-b6ab-7f60cfd01750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.log2(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "341adae3-2352-4a67-8ffd-0b0605bbc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bf36ad6c-4310-4c72-a472-785cac897b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MOYO/mosh2/train/220923_yogi_body_hands_03596_Boat_Pose_or_Paripurna_Navasana_-a_stageii.pkl\" , 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090923e1-1b74-4946-8867-4672d2dd68b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f489b836-06b6-4f71-bc47-2c39d4f9d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"markers_latent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "35a40405-9dd1-4b0c-a257-b84116f6a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = {\n",
    "\n",
    "    \"poses\":data[\"fullpose\"],\n",
    "    \"trans\" : data[\"trans\"],\n",
    "\"betas\" : data[\"betas\"],\n",
    "\"mocap_framerate\" : 30,\n",
    "\"gender\":\"female\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0013c-110a-4df6-82c4-e14ef5a1996e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3d03669e-c865-4569-b475-9ef08ebe5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MOYO/test1.npz\" , **data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "437aa3fb-a3d9-463a-b592-4ec4d1cc14b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x7f85a25e15b0>\n"
     ]
    }
   ],
   "source": [
    "with np.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MOYO/test1.npz\") as data:\n",
    "    # Check for valid AMASS file\n",
    "    print(data)\n",
    "    if (\"trans\" not in data) or (\"gender\" not in data) or ((\"mocap_frame_rate\" not in data) and (\"mocap_framerate\" not in data)) or (\"betas\" not in data) or (\"poses\" not in data):\n",
    "        print(\"Invalid AMASS animation data file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5ad092d1-4d0a-4cd2-9e47-25c57aeb798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/srv/hays-lab/scratch/sanisetty3/music_motion/MOYO/test1.npz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985088d-68aa-4f5f-8ec0-53f7859af97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b9344-eb7a-4a42-b560-ac6680b00350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
