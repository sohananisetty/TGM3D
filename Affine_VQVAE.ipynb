{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8005eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b34652c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b835508",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c9379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13870fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "# from core.datasets.vqa_motion_dataset import VQMotionDataset,DATALoader,VQVarLenMotionDataset,MotionCollator\n",
    "from einops import rearrange, reduce, pack, unpack\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b795d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e4d41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config import cfg, get_cfg_defaults\n",
    "from core.datasets.dataset_loading_utils import load_dataset\n",
    "from core.datasets.vq_dataset import DATALoader\n",
    "from utils.vis_utils import plot_3d_global\n",
    "from core.models.conv_vqvae import ConvVQMotionModel\n",
    "import utils.rotation_conversions as geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb6cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81d9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/TGM3D/checkpoints/conformer_512_1024_affine/conformer_512_1024_affine.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6894ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84005eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.vqvae.motion_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e81871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync is turned on False\n"
     ]
    }
   ],
   "source": [
    "vqvae_model = ConformerVQMotionModel(\n",
    "            cfg.vqvae,\n",
    "            # is_distributed=self.is_distributed,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cedbb8d",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "324cba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 703.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 559.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 368.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motions 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "render_ds, sampler_val, weights_val = load_dataset(\n",
    "                [\"t2m\", \"aist\", \"cm\"],cfg, \"render\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad21dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_dl = DATALoader(\n",
    "    \n",
    "            render_ds, batch_size=2, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab489b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00_000048']\n"
     ]
    }
   ],
   "source": [
    "batch = (next(iter(render_dl)))\n",
    "    \n",
    "print(batch[\"names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f77fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.vis_utils.render_final import Renderer\n",
    "renderer = Renderer(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846bfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f4b81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c1c277c-e910-4fcd-b3ed-34a26919c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(vqvae_model,  path):\n",
    "    path = Path(path)\n",
    "    assert path.exists()\n",
    "    pkg = torch.load(str(path), map_location=\"cuda\")\n",
    "    vqvae_model.vq._codebook.batch_mean = pkg[\"model\"][\n",
    "        \"vq._codebook.batch_mean\"\n",
    "    ]\n",
    "    vqvae_model.vq._codebook.batch_variance = pkg[\"model\"][\n",
    "        \"vq._codebook.batch_variance\"\n",
    "    ]\n",
    "\n",
    "    vqvae_model.load_state_dict(pkg[\"model\"])\n",
    "    vqvae_model = vqvae_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96aa7635-3423-491f-83f6-234e4b54169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.conformer_vqvae import ConformerVQMotionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624aace0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901cc956-76f0-43aa-b6cd-33f7e98b88e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(\"/srv/hays-lab/scratch/sanisetty3/music_motion/TGM3D/checkpoints/conformer_512_1024_affine/conformer_512_1024_affine.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd713c2-4178-4ba2-8853-2fbce89d4527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync is turned on False\n"
     ]
    }
   ],
   "source": [
    "model = ConformerVQMotionModel(cfg.vqvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e3c54c8-5ad1-408f-bf4d-e16a77df1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/srv/hays-lab/scratch/sanisetty3/music_motion/TGM3D/checkpoints/conformer_512_1024_affine/checkpoints/vqvae_motion.320000.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8170243a-a909-4ce7-969c-5c957df9f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(model,save_path)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc87b9bb-7ced-42c2-8fb1-bc22d2ccbd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = model.motionEncoder( torch.randn((1, 80 , 271)).cuda() , True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7215d9-ab58-46b1-a4d9-a49302ca26d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9305d-685b-43c2-bac0-8746bb480a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fcd35571-277b-4c36-888d-b644d4072c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_motion_features = aa.mean() + torch.randn((1, 20 , 768)).to(model.device) * aa.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e254e7aa-1bf3-4b53-8735-362de6834748",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_enc_motion, indices, commit_loss = model.vq(embed_motion_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91f57a12-f9c0-43fc-9b00-0ece08f8ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_motion_features = model.motionDecoder(quantized_enc_motion, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eddf953-35fd-4e85-825f-b73e51156580",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_path = \"/srv/hays-lab/scratch/sanisetty3/music_motion/TGM3D/renders/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fb7af-8b2e-486e-bdf4-76fd01bc44c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a55068-e766-41db-888c-c7079a184cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = np.load('/coc/scratch/sanisetty3/music_motion/GTA/yogi.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be707d05-e856-49ff-b6f8-0b47f472b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892, 66)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"poses\"][:,:66].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dfb1d81-a29d-43db-9ce4-fc92a3ed3c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"trans\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e037355-8d5d-442d-ba72-de3882b735a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rots = geometry.matrix_to_rotation_6d(geometry.axis_angle_to_matrix(torch.Tensor(data[\"poses\"][:,:66].reshape(-1,22,3)))).reshape(-1,132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508c078-44d4-4059-98f8-86a5c57825cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "401726a9-8d61-4539-9920-e7ad9b133cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer.render(\n",
    "                    motion_vec=torch.Tensor(np.concatenate([data[\"trans\"] , rots.numpy()] , 1)),\n",
    "                    outdir=render_path,\n",
    "                    step=0,\n",
    "                    name=\"rnd2\",\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b1a8d-5ae9-44bc-ac79-57fd64da7d77",
   "metadata": {},
   "source": [
    "## New LOss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9e81db7-0f85-44b2-b6a7-424bfcf93411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models.smpl.body_model import BodyModel\n",
    "import utils.rotation_conversions as geomtry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8923d4ee-ce9b-4ec5-9332-cd1ed28d14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = BodyModel(\"/srv/hays-lab/scratch/sanisetty3/music_motion/motion-diffusion-model/body_models/smplh/neutral/model.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdf8770-33bf-4f3c-993d-94e5c46085f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in render_dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7502074-9f18-4998-a753-b67b633f17e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m6d = batch[\"motion\"][:,:,:135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b106fa-084a-41c2-ac6e-3686fd9b62e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 135])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m6d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "524d6aaa-a437-4dde-9e8e-c9908aea49d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs , n , d = m6d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000aef29-320d-4b39-a1cc-05ebf7ae088e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82e12d8c-00f1-4934-ab2b-be18b8f151e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_trans = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "946e77cd-f0e0-4dc8-a8ab-d5e831c1bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = geomtry.matrix_to_axis_angle(geomtry.rotation_6d_to_matrix(m6d[:,:,3:135].reshape(-1,22,6))).reshape(-1 , 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d44c1c36-4543-43fd-9c44-d5dbf2e35618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 66])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372f5ff9-8f29-4657-9652-c45fab766b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "40adbe11-b8cc-420a-b476-d21b9183c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = bm.forward(root_orient=aa[:,:3] , pose_body = aa[:,3:] , trans=m6d[:,:,:3].reshape(-1,3) , return_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9ecd0d94-8066-4b00-b1c0-5f94c1b7a5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['v', 'f', 'Jtr', 'full_pose'])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0df86be4-520d-46e0-a296-eff33916aa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 52, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body[\"Jtr\"].reshape(bs , n , 52,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "70351076-370a-422b-bb19-c9538e2b619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([159, 52, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(body[\"Jtr\"][1:] - body[\"Jtr\"][:-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8958d3e8-4828-417d-a3ab-2b94ac56a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = torch.nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94e6b1d9-e664-437e-9cc0-87fe0ba6e491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loss(body[\"Jtr\"] , body[\"Jtr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0eeed11b-c977-4528-afdc-ad2375a4053b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 271])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m6d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d5de0d9-e9b8-479c-a326-05c724dccf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_new(motion_pred, motion_gt, mask=None):\n",
    "    Loss = torch.nn.SmoothL1Loss()\n",
    "    bs, n, d = motion_gt.shape  ## d = 135\n",
    "    motion_pred_aa = geomtry.matrix_to_axis_angle(\n",
    "        geomtry.rotation_6d_to_matrix(motion_pred[:, :, 3:135].reshape(-1, 22, 6))\n",
    "    ).reshape(-1, 66)\n",
    "    body_pred = bm.forward(\n",
    "        root_orient=motion_pred_aa[:, :3],\n",
    "        pose_body=motion_pred_aa[:, 3:],\n",
    "        trans=motion_pred[:, :, :3].reshape(-1, 3),\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    motion_gt_aa = geomtry.matrix_to_axis_angle(\n",
    "        geomtry.rotation_6d_to_matrix(motion_gt[:, :, 3:135].reshape(-1, 22, 6))\n",
    "    ).reshape(-1, 66)\n",
    "    body_gt = bm.forward(\n",
    "        root_orient=motion_gt_aa[:, :3],\n",
    "        pose_body=motion_gt_aa[:, 3:],\n",
    "        trans=motion_gt[:, :, :3].reshape(-1, 3),\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    j_pred = body_pred[\"Jtr\"].reshape(bs, n, 52, 3)[:, : 22, :]\n",
    "    j_gt = body_gt[\"Jtr\"].reshape(bs, n, 52, 3)[:, : 22, :]\n",
    "\n",
    "    loss_pos = Loss(\n",
    "        j_pred,\n",
    "        j_gt,\n",
    "    )\n",
    "    loss_vel = Loss(\n",
    "        (j_pred[:, 1:] - j_pred[:, :-1]), (j_gt[:, 1:] - j_gt[:, :-1])\n",
    "    )\n",
    "\n",
    "    return loss_pos, loss_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c7b1c73-6af9-420a-8fa4-35591dd35ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_pred, _ , _ = vqvae_model(m6d[:, :, :135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a13cc6e-7e12-4973-ab54-7fffc95dda76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 80, 135])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aac029e0-eeed-412c-9781-03266656662d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1199, grad_fn=<SmoothL1LossBackward0>),\n",
       " tensor(0.0787, grad_fn=<SmoothL1LossBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_new(motion_pred ,m6d )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05fcdea5-e8f3-4982-bf51-f6b52822090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.42843907e-02,  1.13441283e+00, -8.98784186e-03, -2.40984987e-03,\n",
       "       -6.52230864e-04, -9.92232620e-04, -6.47345805e-03,  9.72569679e-01,\n",
       "        1.95284334e-02,  9.65837892e-01, -1.06665792e-01, -2.10577656e-02,\n",
       "        1.12139878e-01,  8.77811686e-01,  2.35941030e-01,  9.67205206e-01,\n",
       "        8.93590907e-02,  2.49379556e-02, -9.78139769e-02,  8.75245933e-01,\n",
       "        2.57273114e-01,  9.84242926e-01, -1.86104024e-02,  8.78357464e-03,\n",
       "        1.86940623e-02,  9.51855687e-01, -1.40547394e-01,  9.64632180e-01,\n",
       "        6.87693139e-02, -4.39669236e-02, -6.46595745e-02,  7.50103124e-01,\n",
       "       -4.13668740e-01,  9.68300201e-01, -5.46530094e-02,  8.35328890e-03,\n",
       "        4.05742119e-02,  7.39468683e-01, -4.42177031e-01,  9.91846624e-01,\n",
       "       -2.63669251e-03, -1.29083900e-02,  2.03791298e-03,  9.82947577e-01,\n",
       "       -6.16558589e-02,  9.84936983e-01, -4.41092218e-04,  6.37313024e-02,\n",
       "       -1.02082998e-02,  9.64401329e-01,  1.14246273e-01,  9.86655531e-01,\n",
       "       -2.35986068e-02, -5.49478645e-02,  3.18845415e-02,  9.64837748e-01,\n",
       "        1.07664388e-01,  9.95877394e-01,  1.04060404e-02,  4.32560868e-03,\n",
       "       -1.04378221e-02,  9.88724033e-01, -3.73103826e-02,  9.98310672e-01,\n",
       "       -6.12182906e-03,  5.28068073e-03,  5.02761189e-03,  9.97152197e-01,\n",
       "        8.36851638e-03,  9.97071286e-01,  7.25011364e-03,  3.04414303e-03,\n",
       "       -7.42382852e-03,  9.96662328e-01,  6.77212252e-04,  9.70232778e-01,\n",
       "        9.14622006e-03,  5.42326719e-03, -1.16296436e-02,  9.73011424e-01,\n",
       "       -3.50353014e-02,  9.21972276e-01,  1.28319900e-01, -6.45643217e-02,\n",
       "       -1.20774008e-01,  9.51249759e-01,  2.24948103e-02,  9.18653932e-01,\n",
       "       -1.07163985e-01,  1.05057156e-01,  1.01283654e-01,  9.51878612e-01,\n",
       "        3.23987403e-02,  9.85577040e-01, -1.01251840e-02,  2.29271893e-03,\n",
       "        8.80151979e-03,  9.73926622e-01,  1.24900396e-02,  6.26414120e-01,\n",
       "        5.63514330e-01, -2.37688198e-01, -5.40599279e-01,  6.73453504e-01,\n",
       "        8.01574207e-02,  6.37091834e-01, -5.48648146e-01,  2.40276587e-01,\n",
       "        5.04014381e-01,  6.86635257e-01,  1.32857638e-01,  4.79215240e-01,\n",
       "       -4.85518128e-02, -5.24101036e-01,  4.94350531e-02,  8.64559209e-01,\n",
       "       -3.68378402e-02,  4.57128376e-01,  3.07083826e-02,  5.39087418e-01,\n",
       "       -8.11344916e-02,  8.65124037e-01,  9.13718833e-03,  9.13432982e-01,\n",
       "       -3.58531085e-02, -3.69453652e-02,  3.63194239e-02,  8.88084743e-01,\n",
       "       -1.97448431e-02,  9.20908617e-01,  3.26237721e-02,  3.07632488e-02,\n",
       "       -3.58863521e-02,  8.87982305e-01,  3.40894737e-03])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"../HumanMotionSMPL/Mean.npy\")["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135fd5a-48f0-4400-8e54-74ee9b30f17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a28510f-681d-4923-8ec8-5d98ddc86d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/coc/scratch/sanisetty3/music_motion/TGM3D'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39ecd7b8-8dda-4a06-836a-c43788142fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/coc/scratch/sanisetty3/PyMAF-X\n"
     ]
    }
   ],
   "source": [
    "cd PyMAF-X/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dedc07-2d98-4b81-bee9-4df38cbf7e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8298abf-b95b-441e-aa70-0d9c2dff5f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c278d73-6c67-4376-81ac-3fe4a57289fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5043cf-d65f-4d70-adfc-aab0d894d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m apps.demo_smplx --image_folder examples/coco_images --detection_threshold 0.3 --pretrained_model data/pretrained_model/PyMAF-X_model_checkpoint_v1.1.pt --misc TRAIN.BHF_MODE full_body MODEL.PyMAF.HAND_VIS_TH 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
